import gradio as gr
from diffusers import StableDiffusionPipeline, StableDiffusionXLPipeline
import torch
import gc
import os

# å®šç¾©å¯ç”¨çš„æ¨¡å‹ (æ·»åŠ ç®¡é“ç±»å‹ä¿¡æ¯)
MODELS = {
    "Stable Diffusion v1.5": {
        "path": "./models/stable-diffusion-v1-5",
        "class": StableDiffusionPipeline
    },
    "Stable Diffusion XL": {
        "path": "./models/sdxl-base-1.0",
        "class": StableDiffusionXLPipeline
    }
}

# å¯é¸é¢¨æ ¼æç¤º
STYLE_PRESETS = {
    "åŸå§‹é¢¨æ ¼": "",
    "å‹•æ¼«é¢¨": "anime style, cel-shading, colorful",
    "ç¾å¯¦æ”å½±": "photorealistic, DSLR, 8k",
    "æ²¹ç•«é¢¨": "oil painting, canvas texture, brush strokes",
    "çš®å…‹æ–¯é¢¨": "pixar style, cartoon, 3d rendered, expressive eyes",
    "æµ®ä¸–ç¹ª": "ukiyo-e, japanese woodblock print, traditional style",
    "é¦¬è³½å…‹é¢¨": "mosaic style, broken tiles, abstract shapes",
    "å‰æ™®åŠ›é¢¨": "Studio Ghibli style, whimsical, detailed environment, soft colors",
    "ç§‘å¹»é¢¨": "sci-fi, futuristic, neon lights, cyberpunk",
    "å¥‡å¹»é¢¨": "fantasy, magical, mythical creatures, epic landscapes",  
}

# å…¨åŸŸè®Šæ•¸å„²å­˜ç•¶å‰æ¨¡å‹
current_pipe = None
current_model = None

def load_model(model_name):
    global current_pipe, current_model
    
    if current_model == model_name and current_pipe is not None:
        return f"âœ… æ¨¡å‹ {model_name} å·²è¼‰å…¥"
    
    # æ¸…é™¤å‰ä¸€å€‹æ¨¡å‹
    if current_pipe is not None:
        del current_pipe
        gc.collect()
        torch.cuda.empty_cache()
    
    try:
        model_info = MODELS.get(model_name)
        if not model_info:
            return f"âŒ æ‰¾ä¸åˆ°æ¨¡å‹è¨­å®š: {model_name}"
        
        model_path = model_info["path"]
        model_class = model_info["class"]
        
        # åˆ¤æ–·æ˜¯è³‡æ–™å¤¾é‚„æ˜¯å–®ä¸€æª”æ¡ˆ
        if os.path.isfile(os.path.join(model_path, "model.safetensors")):
            # ä½¿ç”¨ from_single_file è¼‰å…¥
            current_pipe = model_class.from_single_file(
                os.path.join(model_path, "model.safetensors"),
                torch_dtype=torch.float16,
                use_safetensors=True,
                local_files_only=True
            ).to("cuda")
        else:
            # ä½¿ç”¨ from_pretrained è¼‰å…¥è³‡æ–™å¤¾
            current_pipe = model_class.from_pretrained(
                model_path,
                torch_dtype=torch.float16,
                use_safetensors=True,
                local_files_only=True
            ).to("cuda")
        
        current_model = model_name
        return f"âœ… æˆåŠŸè¼‰å…¥æ¨¡å‹: {model_name}"
        
    except Exception as e:
        return f"âŒ è¼‰å…¥æ¨¡å‹å¤±æ•—: {str(e)}"


def generate_image(prompt, style, model_name):
    global current_pipe, current_model
    
    # æª¢æŸ¥æ˜¯å¦éœ€è¦åˆ‡æ›æ¨¡å‹
    if current_model != model_name or current_pipe is None:
        load_status = load_model(model_name)
        if load_status is None or "âŒ" in load_status:
            return None, load_status or "âŒ æœªçŸ¥éŒ¯èª¤"
    
    try:
        full_prompt = f"{prompt}, {STYLE_PRESETS.get(style, '')}"
        
        with torch.inference_mode():
            # æ·»åŠ å¼‚å¸¸å¤„ç†ä»¥ç¡®ä¿å›¾åƒç”Ÿæˆ
            try:
                image = current_pipe(
                    full_prompt,
                    num_inference_steps=25 if "XL" in model_name else 20,
                    guidance_scale=8.0 if "XL" in model_name else 7.5,
                    width=1024 if "XL" in model_name else 512,
                    height=1024 if "XL" in model_name else 512
                ).images[0]
            except Exception as e:
                return None, f"âŒ ç”Ÿæˆéç¨‹ä¸­å‡ºéŒ¯: {str(e)}"
        
        return image, f"âœ… åœ–ç‰‡ç”Ÿæˆå®Œæˆï¼ä½¿ç”¨æ¨¡å‹: {current_model}"
    except Exception as e:
        return None, f"âŒ ç”Ÿæˆå¤±æ•—: {str(e)}"

# åˆå§‹åŒ–é è¨­æ¨¡å‹
def initialize_default_model():
    """åˆå§‹åŒ–é è¨­æ¨¡å‹"""
    default_model = list(MODELS.keys())[0]  # ä½¿ç”¨ç¬¬ä¸€å€‹æ¨¡å‹ä½œç‚ºé è¨­
    return load_model(default_model)

# Gradio UI è¨­è¨ˆ
with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.Markdown("# ğŸ–¼ï¸ æ–‡ç”Ÿåœ–ï¼šæœ¬åœ° AI åœ–ç‰‡ç”Ÿæˆå™¨")
    gr.Markdown("æ”¯æ´å¤šæ¨¡å‹åˆ‡æ›çš„ Stable Diffusion åœ–ç‰‡ç”Ÿæˆå·¥å…·")
    
    # æ¨¡å‹é¸æ“‡å€åŸŸ
    with gr.Row():
        model_dropdown = gr.Dropdown(
            choices=list(MODELS.keys()), 
            label="ğŸ¤– é¸æ“‡æ¨¡å‹", 
            value=list(MODELS.keys())[0],
            info="é¸æ“‡è¦ä½¿ç”¨çš„ AI æ¨¡å‹"
        )
        load_model_btn = gr.Button("ğŸ”„ è¼‰å…¥æ¨¡å‹", variant="secondary")
    
    # æ¨¡å‹ç‹€æ…‹é¡¯ç¤º
    model_status = gr.Textbox(
        label="æ¨¡å‹ç‹€æ…‹", 
        value="è«‹é¸æ“‡æ¨¡å‹ä¸¦é»æ“Šã€Œè¼‰å…¥æ¨¡å‹ã€æŒ‰éˆ•",
        interactive=False
    )
    
    gr.Markdown("---")
    
    # åœ–ç‰‡ç”Ÿæˆå€åŸŸ
    with gr.Row():
        with gr.Column(scale=1):
            prompt_input = gr.Textbox(
                label="ğŸ“ Prompt æè¿°", 
                placeholder="ä¾‹å¦‚: a beautiful landscape with mountains and lakes",
                lines=3
            )
            style_dropdown = gr.Dropdown(
                choices=list(STYLE_PRESETS.keys()), 
                label="ğŸ¨ é¢¨æ ¼é¸æ“‡", 
                value="åŸå§‹é¢¨æ ¼"
            )
            
            with gr.Row():
                generate_button = gr.Button("ğŸ–¼ï¸ ç”Ÿæˆåœ–ç‰‡", variant="primary", scale=2)
                clear_button = gr.Button("ğŸ—‘ï¸ æ¸…é™¤", variant="secondary", scale=1)
        
        with gr.Column(scale=1):
            output_image = gr.Image(label="ç”Ÿæˆçµæœ", type="pil", height=400)
            generation_status = gr.Textbox(
                label="ç”Ÿæˆç‹€æ…‹", 
                value="æº–å‚™å°±ç·’",
                interactive=False
            )
    
    # ç¯„ä¾‹æç¤ºè©
    gr.Markdown("### ğŸ’¡ ç¯„ä¾‹æç¤ºè©")
    example_prompts = [
        "1girl, anime style, cute face, big eyes, looking at viewer, detailed eyes, long hair, school uniform, sitting on a bench, soft light, cherry blossoms, spring, highly detailed, perfect lighting, masterpiece, anime background",
        "A peaceful countryside landscape, in the style of Studio Ghibli, soft colors, dreamy atmosphere, detailed environment, anime style, hand-drawn look, gentle lighting, cinematic compositionï¼Œa Boy and a girl running hand in hand on forest path",
        "anime style, warrior girl, long flowing hair, armor, holding sword, dynamic pose, glowing effects, fantasy landscape, dramatic lighting, cinematic, epic, intricate details, masterpiece",
        "anime style, night cityscape, neon lights, futuristic, girl walking in the rain, umbrella, reflections on the ground, detailed background, soft light, cyberpunk vibes, high quality, masterpiece"
    ]
    
    with gr.Row():
        for prompt in example_prompts:
            gr.Button(prompt, size="sm").click(
                lambda p=prompt: p, 
                outputs=prompt_input
            )
    
    # äº‹ä»¶è™•ç†
    load_model_btn.click(
        fn=load_model,
        inputs=[model_dropdown],
        outputs=[model_status]
    )
    
    generate_button.click(
        fn=generate_image,
        inputs=[prompt_input, style_dropdown, model_dropdown],
        outputs=[output_image, generation_status]
    )
    
    clear_button.click(
        lambda: (None, "", "å·²æ¸…é™¤"),
        outputs=[output_image, prompt_input, generation_status]
    )
    
    # æ¨¡å‹ä¸‹æ‹‰é¸å–®è®Šæ›´æ™‚çš„æç¤º
    model_dropdown.change(
        lambda model: f"ğŸ’¡ å·²é¸æ“‡ {model}ï¼Œè«‹é»æ“Šã€Œè¼‰å…¥æ¨¡å‹ã€æŒ‰éˆ•",
        inputs=[model_dropdown],
        outputs=[model_status]
    )

    # å•Ÿå‹•æ™‚åˆå§‹åŒ–é è¨­æ¨¡å‹
    demo.load(
        fn=initialize_default_model,
        outputs=[model_status]
    )

# å•Ÿå‹•æœ¬åœ°æœå‹™
if __name__ == "__main__":
    demo.launch()